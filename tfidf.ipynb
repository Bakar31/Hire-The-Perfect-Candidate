{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# required libraries\r\n",
    "import os\r\n",
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "from pdfminer import high_level\r\n",
    "\r\n",
    "train = pd.read_csv('dataset/train.csv')\r\n",
    "test = pd.read_csv('dataset/test.csv')\r\n",
    "\r\n",
    "#paths\r\n",
    "train_path = \"dataset/trainResumes/\"\r\n",
    "test_path = \"dataset/testResumes/\"\r\n",
    "\r\n",
    "# epty list for resumes text\r\n",
    "train_resumes = []\r\n",
    "test_resumes = []\r\n",
    "\r\n",
    "# ids\r\n",
    "ids = list(train.CandidateID)\r\n",
    "test_ids = list(test.CandidateID)\r\n",
    "\r\n",
    "# pdf2string\r\n",
    "def pdf2string_train(path, ids, resumes):\r\n",
    "    for i in ids:\r\n",
    "        main_path = path+i+'.pdf'\r\n",
    "        text = high_level.extract_text(main_path)\r\n",
    "        str_list = text.split()\r\n",
    "        str_list = str_list[:]\r\n",
    "        string = ' '.join(str_list)\r\n",
    "        resumes.append(string)\r\n",
    "        \r\n",
    "\r\n",
    "def pdf2string_test(path, test_ids, resumes):\r\n",
    "    for i in test_ids:\r\n",
    "        main_path = path+i+'.pdf'\r\n",
    "        text = high_level.extract_text(main_path)\r\n",
    "        str_list = text.split()\r\n",
    "        str_list = str_list[:]\r\n",
    "        string = ' '.join(str_list)\r\n",
    "        resumes.append(string)\r\n",
    "\r\n",
    "\r\n",
    "pdf2string_train(train_path, ids, train_resumes)\r\n",
    "pdf2string_test(test_path,  test_ids, test_resumes)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "train_resumes[0]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'L I A M A N D R E W S F R E S H E R WORK EXPERIENCE DICTIS making. Intern Trainee, Jan 2020 to Apr 2020 Responsible for performing and helping in decision EXECUTIVE SUMMARY Fresher with strong statistical and analytic capabilities. Someone who is driven by the passion for problem solving. Though I am from Civil Engineering background I have always been fascinated with data and how Machine Learning is evolving with iit. PERSONAL SKILLS Data Analyst, Data Mining, Data Visualization, Machine Learning, Linear Regression, Statistical Modeling, Predictive Modeling, SQL Server, Oracle, Python. PROJECTS EXTRA-CURRICULARS Data Preprocessing with Python Data Visualization with Power BI ACADEMIC PROFILE Railway Signals Determiner using relay weight system. 2020 B.Tech(Civil) Garodia Institute of Technosciences,'"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "single_words = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z']\r\n",
    "def remove_single_word(text):\r\n",
    "    resume = []\r\n",
    "    for i in text.split():\r\n",
    "        if i not in single_words:\r\n",
    "            resume.append(i)\r\n",
    "    return ' '.join(resume)\r\n",
    "\r\n",
    "train_resumes_str = []\r\n",
    "for resume in train_resumes:\r\n",
    "    string = remove_single_word(resume)\r\n",
    "    train_resumes_str.append(string)\r\n",
    "\r\n",
    "test_resumes_str = []\r\n",
    "for resume in test_resumes:\r\n",
    "    string = remove_single_word(resume)\r\n",
    "    test_resumes_str.append(string)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "train_resumes_str[0]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'WORK EXPERIENCE DICTIS making. Intern Trainee, Jan 2020 to Apr 2020 Responsible for performing and helping in decision EXECUTIVE SUMMARY Fresher with strong statistical and analytic capabilities. Someone who is driven by the passion for problem solving. Though am from Civil Engineering background have always been fascinated with data and how Machine Learning is evolving with iit. PERSONAL SKILLS Data Analyst, Data Mining, Data Visualization, Machine Learning, Linear Regression, Statistical Modeling, Predictive Modeling, SQL Server, Oracle, Python. PROJECTS EXTRA-CURRICULARS Data Preprocessing with Python Data Visualization with Power BI ACADEMIC PROFILE Railway Signals Determiner using relay weight system. 2020 B.Tech(Civil) Garodia Institute of Technosciences,'"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "import re\r\n",
    "import nltk\r\n",
    "import spacy\r\n",
    "import string\r\n",
    "from nltk.corpus import stopwords\r\n",
    "from nltk.corpus import wordnet\r\n",
    "from nltk.stem import WordNetLemmatizer\r\n",
    "\r\n",
    "train_resumes_lower = []\r\n",
    "for resume in train_resumes_str:\r\n",
    "    train_resumes_lower.append(resume.lower())\r\n",
    "\r\n",
    "test_resumes_lower = []\r\n",
    "for resume in test_resumes_str:\r\n",
    "    test_resumes_lower.append(resume.lower())\r\n",
    "\r\n",
    "PUNCT_TO_REMOVE = string.punctuation\r\n",
    "#print(PUNCT_TO_REMOVE)\r\n",
    "#print(type(PUNCT_TO_REMOVE))\r\n",
    "def remove_punctuation(text):\r\n",
    "    return text.translate(str.maketrans('', '', PUNCT_TO_REMOVE))\r\n",
    "\r\n",
    "train_punc_removed = []\r\n",
    "for resume in train_resumes_lower:\r\n",
    "    punc_removed = remove_punctuation(resume)\r\n",
    "    train_punc_removed.append(punc_removed)\r\n",
    "\r\n",
    "test_punc_removed = []\r\n",
    "for resume in test_resumes_lower:\r\n",
    "    punc_removed = remove_punctuation(resume)\r\n",
    "    test_punc_removed.append(punc_removed)\r\n",
    "\r\n",
    "STOPWORDS = set(stopwords.words('english'))\r\n",
    "def remove_stopwords(text):\r\n",
    "    return \" \".join([word for word in str(text).split() if word not in STOPWORDS])\r\n",
    "\r\n",
    "train_stopwords_removed = []\r\n",
    "for resume in train_punc_removed:\r\n",
    "    stopwords_removed = remove_stopwords(resume)\r\n",
    "    train_stopwords_removed.append(stopwords_removed)\r\n",
    "\r\n",
    "test_stopwords_removed = []\r\n",
    "for resume in test_punc_removed:\r\n",
    "    stopwords_removed = remove_stopwords(resume)\r\n",
    "    test_stopwords_removed.append(stopwords_removed)\r\n",
    "\r\n",
    "lemmatizer = WordNetLemmatizer()\r\n",
    "wordnet_map = {\"N\":wordnet.NOUN, \"V\":wordnet.VERB, \"J\":wordnet.ADJ, \"R\":wordnet.ADV}\r\n",
    "def lemmatize_words(text):\r\n",
    "    pos_tagged_text = nltk.pos_tag(text.split())\r\n",
    "    return \" \".join([lemmatizer.lemmatize(word, wordnet_map.get(pos[0], wordnet.NOUN)) for word, pos in pos_tagged_text])\r\n",
    "\r\n",
    "train_lemma = []\r\n",
    "for resume in train_stopwords_removed:\r\n",
    "    lemma = lemmatize_words(resume)\r\n",
    "    train_lemma.append(lemma)\r\n",
    "\r\n",
    "test_lemma = []\r\n",
    "for resume in test_stopwords_removed:\r\n",
    "    lemma = lemmatize_words(resume)\r\n",
    "    test_lemma.append(lemma)\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "train_lemma[0]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'work experience dictis make intern trainee jan 2020 apr 2020 responsible perform help decision executive summary fresher strong statistical analytic capability someone drive passion problem solve though civil engineering background always fascinate data machine learn evolve iit personal skill data analyst data mining data visualization machine learn linear regression statistical model predictive modeling sql server oracle python project extracurriculars data preprocessing python data visualization power bi academic profile railway signal determiner use relay weight system 2020 btechcivil garodia institute technosciences'"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "test_lemma[0]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'grace bailry personal profile work background software engineer work several computer vision project end end deployment look join machine learn developer closely work problem increase grasp domain eximius design pvt ltd company software development deployment engineer apr 2019 till date implement multiple component face identification system include face alignment landmark detection improve validation pipeline face recognition collect data different lighting condition perform image manipulation operation data increase accuracy pipeline skill education software engineerdeveloper software development project management machine learn computer vision opencv python c ruby learn algorithm btech electronics computer dvr college engineering technology 2017 post graduation software development cdac noida 2019 project activity scalable project deployment sdlc pioneer deployment end end ml project kvcc20 workshop clustering image base feature management create recommender system understand false alarm support side real time service'"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "import pandas as pd\r\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\r\n",
    "\r\n",
    "train = pd.read_csv('dataset/train.csv')\r\n",
    "test = pd.read_csv('dataset/test.csv')\r\n",
    "\r\n",
    "train_df = pd.concat([train, pd.DataFrame(train_lemma, columns=['resumes'])], axis = 1)\r\n",
    "test_df = pd.concat([test, pd.DataFrame(test_lemma, columns=['resumes'])], axis = 1)\r\n",
    "\r\n",
    "print(train_df.head())\r\n",
    "print(test_df.head())\r\n",
    "\r\n",
    "tfidf = TfidfVectorizer(max_features=10000, \r\n",
    "                        strip_accents='unicode', \r\n",
    "                        analyzer='word',\r\n",
    "                        lowercase=False,\r\n",
    "                        ngram_range=(1, 1), \r\n",
    "                        stop_words = 'english')\r\n",
    "\r\n",
    "tfidf_matrix_train = tfidf.fit_transform(train_df['resumes'])\r\n",
    "tfidf_matrix_test = tfidf.transform(test_df['resumes'])\r\n",
    "print(tfidf_matrix_train.shape)\r\n",
    "print(tfidf_matrix_test.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "     CandidateID  Match Percentage  \\\n",
      "0  candidate_011             13.60   \n",
      "1  candidate_113             36.63   \n",
      "2  candidate_123             54.93   \n",
      "3  candidate_012             41.46   \n",
      "4  candidate_002             48.91   \n",
      "\n",
      "                                             resumes  \n",
      "0  work experience dictis make intern trainee jan...  \n",
      "1  ellie mackey executive profile work experience...  \n",
      "2  fresher skill project activites fresher knowle...  \n",
      "3  jimmy gartner professional profile employment ...  \n",
      "4  associate analyst skill certify data analyst d...  \n",
      "     CandidateID                                            resumes\n",
      "0  candidate_014  grace bailry personal profile work background ...\n",
      "1  candidate_098  software engineer skill assistant software eng...\n",
      "2  candidate_075  keiron pavard personal profile work background...\n",
      "3  candidate_016  work experience na academic profile btechcompu...\n",
      "4  candidate_131  zachary perez good knowledge c oops concept go...\n",
      "(90, 1872)\n",
      "(60, 1872)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "import xgboost as XGB"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "y = train_df['Match Percentage']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.model_selection import GridSearchCV\r\n",
    "xgb_grid = {'learning_rate': [0.1, 0.3, 0.2, 0.01, 0.02, 0.03, 0.04, 0.05, 0.07, 0.005, 0.006, 0.007, 0.0075, 0.008],\r\n",
    "            'n_estimators': [100, 200, 300, 400, 500, 600, 700, 800, 900, 1000, 1100, 1200],\r\n",
    "            'max_depth': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 14, 20]}\r\n",
    "\r\n",
    "\r\n",
    "xgb = GridSearchCV(XGB.XGBRegressor(),\r\n",
    "                    param_grid = xgb_grid,\r\n",
    "                    cv=2,\r\n",
    "                    verbose=True)\r\n",
    "xgb.fit(tfidf_matrix_train, y)\r\n",
    "xgb.best_params_"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "\r\n",
    "xgb = XGB.XGBRegressor(learning_rate=0.005, \r\n",
    "                        n_estimators=700, \r\n",
    "                        objective='reg:squarederror', \r\n",
    "                        max_depth=8, \r\n",
    "                        reg_lambda = 1.3,\r\n",
    "                        gamma = 1,\r\n",
    "                        min_child_weight =1.5,\r\n",
    "                        max_delta_step = 100,\r\n",
    "                        random_state = 31).fit(tfidf_matrix_train, y)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "from lightgbm import LGBMRegressor\r\n",
    "lgbm = LGBMRegressor(num_leaves=31,\r\n",
    "                    learning_rate = 0.01,\r\n",
    "                    n_estimators = 1000,\r\n",
    "                    reg_lambda = 2.5,\r\n",
    "                    reg_alpha = 2,\r\n",
    "                    random_state=31).fit(tfidf_matrix_train, y)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from catboost import CatBoostRegressor\r\n",
    "cat = CatBoostRegressor().fit(tfidf_matrix_train, y)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "def submission(model, test_sentences):\r\n",
    "    test1 = pd.read_csv('dataset/test.csv')\r\n",
    "    preds = model.predict(test_sentences)\r\n",
    "    prediction = pd.DataFrame(preds, columns = ['Match Percentage'])\r\n",
    "    sub_df = pd.concat([test1, prediction], axis = 1)\r\n",
    "    return sub_df\r\n",
    "\r\n",
    "sub = submission(lgbm, tfidf_matrix_test)\r\n",
    "sub.to_csv('submission file/lgbm sub.csv')\r\n",
    "print(sub.head(10))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "     CandidateID  Match Percentage\n",
      "0  candidate_014         24.703401\n",
      "1  candidate_098         34.180648\n",
      "2  candidate_075         35.837480\n",
      "3  candidate_016         34.463944\n",
      "4  candidate_131         32.880330\n",
      "5  candidate_056         36.103730\n",
      "6  candidate_141         48.279395\n",
      "7  candidate_044         56.433841\n",
      "8  candidate_029         31.381907\n",
      "9  candidate_120         41.584013\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(sub.head(10))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5 64-bit"
  },
  "interpreter": {
   "hash": "0bd2b4fb9f3446da4d8f55e0ab2f46c8924547cca4f6669133edbde87e094ed0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}