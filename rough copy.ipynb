{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# required libraries\r\n",
    "import os\r\n",
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "from pdfminer import high_level\r\n",
    "\r\n",
    "#paths\r\n",
    "train_path = \"dataset/trainResumes/\"\r\n",
    "test_path = \"dataset/testResumes/\"\r\n",
    "\r\n",
    "# epty list for resumes text\r\n",
    "train_resumes = []\r\n",
    "test_resumes = []\r\n",
    "\r\n",
    "# pdf2string\r\n",
    "def pdf2string(path, resumes):\r\n",
    "    for i in os.listdir(path):\r\n",
    "        main_path = path+i\r\n",
    "        text = high_level.extract_text(main_path)\r\n",
    "        str_list = text.split()\r\n",
    "        str_list = str_list[:]\r\n",
    "        string = ' '.join(str_list)\r\n",
    "        resumes.append(string)\r\n",
    "\r\n",
    "pdf2string(train_path, train_resumes)\r\n",
    "pdf2string(test_path, test_resumes)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "import spacy\r\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\r\n",
    "nlp = spacy.load('en_core_web_sm')\r\n",
    "\r\n",
    "needless_words = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U',\r\n",
    "'V', 'W', 'X', 'Y', 'Z']\r\n",
    "punctuations = list('''!()-[]{};:'\"\\,<>./?@#$%^&*_~''')\r\n",
    "\r\n",
    "def text_processing(resume):   \r\n",
    "\r\n",
    "    resume = nlp(resume)\r\n",
    "    token_list = []\r\n",
    "    for token in resume:\r\n",
    "        token_list.append(token.text)\r\n",
    "\r\n",
    "    filtered_sentence =[] \r\n",
    "    for word in token_list:\r\n",
    "        lexeme = nlp.vocab[word]\r\n",
    "        if lexeme.is_stop == False:\r\n",
    "            filtered_sentence.append(word) \r\n",
    "\r\n",
    "    # further filter\r\n",
    "    filtered_sentence_2 = []\r\n",
    "    for word in filtered_sentence:\r\n",
    "        if word not in needless_words:\r\n",
    "            filtered_sentence_2.append(word)\r\n",
    "\r\n",
    "    filtered_sentence_3 = []\r\n",
    "    for word in filtered_sentence_2:\r\n",
    "        if word not in punctuations:\r\n",
    "            filtered_sentence_3.append(word)\r\n",
    "    \r\n",
    "    Stem_words = []\r\n",
    "    sentence = ' '.join(filtered_sentence_3)\r\n",
    "    doc = nlp(sentence)\r\n",
    "    for word in doc:\r\n",
    "        Stem_words.append(word.lemma_)\r\n",
    "\r\n",
    "    main_text = ' '.join(Stem_words)\r\n",
    "    main_text = main_text.lower()\r\n",
    "    return main_text"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "processed_resumes_train = []\r\n",
    "processed_resumes_test = []\r\n",
    "\r\n",
    "for  resume in train_resumes:\r\n",
    "    processed_resume = text_processing(resume)\r\n",
    "    processed_resumes_train.append(processed_resume)\r\n",
    "\r\n",
    "for  resume in test_resumes:\r\n",
    "    processed_resume = text_processing(resume)\r\n",
    "    processed_resumes_test.append(processed_resume)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "print(len(processed_resumes_train))\r\n",
    "print(len(processed_resumes_test))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "90\n",
      "60\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "print(processed_resumes_train[2])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "associate analyst skills certified data analyst degree electronics engineering hand experience analyze interpret datum good numerical accuracy python machine learning mysql data mining deep learning data analysis computer vision flask api predictive modeling aws scikit learn numpy statistical analysis multivariate analysis decision trees random forest xgboost nlp project work experience deep learning base pattern match auto color grade python amz loans mortgages erc analytics jun 2019 till date qualification google cloud certified handling datum employee find retention factor employee satisfaction worked closely hr team find balance beneficial employee company education b.tech b.e. electronics telecommunication nagpur university 2019\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "train = pd.read_csv('dataset/train.csv')\r\n",
    "test = pd.read_csv('dataset/test.csv')\r\n",
    "\r\n",
    "def dataframe(resume_list, df):\r\n",
    "    resumes =  pd.DataFrame(resume_list, columns = ['resumes'])\r\n",
    "    dataframe = pd.concat([df, resumes], axis = 1)\r\n",
    "    dataframe.drop('CandidateID', axis = 1, inplace = True)\r\n",
    "    return dataframe\r\n",
    "\r\n",
    "train_df = dataframe(processed_resumes_train, train)\r\n",
    "test_df = dataframe(processed_resumes_test, test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "train_df.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   Match Percentage                                            resumes\n",
       "0             13.60  jacob smith personal profile work background a...\n",
       "1             36.63  brianna williams executive profile work experi...\n",
       "2             54.93  associate analyst skills certified data analys...\n",
       "3             41.46  python machine learn deep learning data analys...\n",
       "4             48.91  jennifer armstrong fresher computer vision mac..."
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Match Percentage</th>\n",
       "      <th>resumes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13.60</td>\n",
       "      <td>jacob smith personal profile work background a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36.63</td>\n",
       "      <td>brianna williams executive profile work experi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>54.93</td>\n",
       "      <td>associate analyst skills certified data analys...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>41.46</td>\n",
       "      <td>python machine learn deep learning data analys...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>48.91</td>\n",
       "      <td>jennifer armstrong fresher computer vision mac...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "x = train_df.drop('Match Percentage', axis = 1)\r\n",
    "y = train_df['Match Percentage']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "from sklearn.model_selection import train_test_split\r\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "count_vectorizer = CountVectorizer(stop_words='english')\r\n",
    "count_train = count_vectorizer.fit_transform(x)\r\n",
    "count_test = count_vectorizer.transform(test_df)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "count_train"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<1x1 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 1 stored elements in Compressed Sparse Row format>"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import re"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# train features\r\n",
    "train_df['words_counts'] = train_df['resumes'].apply(lambda x: len(str(x).split()))\r\n",
    "train_df['char_counts'] = train_df['resumes'].apply(lambda x: len(str(x)))\r\n",
    "train_df['avg_word_len'] = train_df['char_counts']/train_df['words_counts']\r\n",
    "train_df['ml_counts'] = train_df['resumes'].apply(lambda x: len(re.findall('machine learning', x)))\r\n",
    "train_df['ml_engineer_counts'] = train_df['resumes'].apply(lambda x: len(re.findall('machine learning engineer', x)))\r\n",
    "train_df['analytics_counts'] = train_df['resumes'].apply(lambda x: len(re.findall('analytics', x)))\r\n",
    "train_df['degree_counts'] = train_df['resumes'].apply(lambda x: len(re.findall('master degree', x)))\r\n",
    "train_df['degree_counts_2'] = train_df['resumes'].apply(lambda x: len(re.findall('msc', x)))\r\n",
    "train_df['degree_counts_3'] = train_df['resumes'].apply(lambda x: len(re.findall('degree', x)))\r\n",
    "train_df['deep_learning_counts'] = train_df['resumes'].apply(lambda x: len(re.findall('deep learning', x)))\r\n",
    "train_df['tf_counts'] = train_df['resumes'].apply(lambda x: len(re.findall('tensorflow', x)))\r\n",
    "train_df['neural_network_counts'] = train_df['resumes'].apply(lambda x: len(re.findall('neural network', x)))\r\n",
    "train_df['nlp_counts'] = train_df['resumes'].apply(lambda x: len(re.findall('natural language processing', x)))\r\n",
    "train_df['nlp_counts_2'] = train_df['resumes'].apply(lambda x: len(re.findall('nlp', x)))\r\n",
    "train_df['pyspark_counts'] = train_df['resumes'].apply(lambda x: len(re.findall('pyspark', x)))\r\n",
    "train_df['hadoop_counts'] = train_df['resumes'].apply(lambda x: len(re.findall('hadoop', x)))\r\n",
    "train_df['data_analysis_counts'] = train_df['resumes'].apply(lambda x: len(re.findall('data analysis', x)))\r\n",
    "train_df['lustering_counts'] = train_df['resumes'].apply(lambda x: len(re.findall('clustering', x)))\r\n",
    "train_df['lr_counts'] = train_df['resumes'].apply(lambda x: len(re.findall('logistic regression', x)))\r\n",
    "train_df['classification_counts'] = train_df['resumes'].apply(lambda x: len(re.findall('classification', x)))\r\n",
    "train_df['sk_counts'] = train_df['resumes'].apply(lambda x: len(re.findall('sciKit learn', x)))\r\n",
    "train_df['pytorch_counts'] = train_df['resumes'].apply(lambda x: len(re.findall('pytorch', x)))\r\n",
    "train_df['cnn_counts'] = train_df['resumes'].apply(lambda x: len(re.findall('cnn', x)))\r\n",
    "train_df['rnn_counts'] = train_df['resumes'].apply(lambda x: len(re.findall('rnn', x)))\r\n",
    "train_df['gans_counts'] = train_df['resumes'].apply(lambda x: len(re.findall('gans', x)))\r\n",
    "train_df['nltk_counts'] = train_df['resumes'].apply(lambda x: len(re.findall('nltk', x)))\r\n",
    "train_df['spacy_counts'] = train_df['resumes'].apply(lambda x: len(re.findall('spacy', x)))\r\n",
    "train_df['transformer_counts'] = train_df['resumes'].apply(lambda x: len(re.findall('transformer', x)))\r\n",
    "train_df['django_counts'] = train_df['resumes'].apply(lambda x: len(re.findall('django', x)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "train_df['feature1'] = train_df['neural_network_counts'] + train_df['tf_counts'] + train_df['ml_counts']\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# test features\r\n",
    "test_df['words_counts'] = test_df['resumes'].apply(lambda x: len(str(x).split()))\r\n",
    "test_df['char_counts'] = test_df['resumes'].apply(lambda x: len(str(x)))\r\n",
    "test_df['avg_word_len'] = test_df['char_counts']/train_df['words_counts']\r\n",
    "test_df['ml_counts'] = test_df['resumes'].apply(lambda x: len(re.findall('machine learning', x)))\r\n",
    "test_df['ml_engineer_counts'] = test_df['resumes'].apply(lambda x: len(re.findall('machine learning engineer', x)))\r\n",
    "test_df['analytics_counts'] = test_df['resumes'].apply(lambda x: len(re.findall('analytics', x)))\r\n",
    "test_df['degree_counts'] = test_df['resumes'].apply(lambda x: len(re.findall('master degree', x)))\r\n",
    "test_df['degree_counts_2'] = test_df['resumes'].apply(lambda x: len(re.findall('msc', x)))\r\n",
    "test_df['degree_counts_3'] = test_df['resumes'].apply(lambda x: len(re.findall('degree', x)))\r\n",
    "test_df['deep_learning_counts'] = test_df['resumes'].apply(lambda x: len(re.findall('deep learning', x)))\r\n",
    "test_df['tf_counts'] = test_df['resumes'].apply(lambda x: len(re.findall('tensorflow', x)))\r\n",
    "test_df['neural_network_counts'] = test_df['resumes'].apply(lambda x: len(re.findall('neural network', x)))\r\n",
    "test_df['nlp_counts'] = test_df['resumes'].apply(lambda x: len(re.findall('natural language processing', x)))\r\n",
    "test_df['nlp_counts_2'] = test_df['resumes'].apply(lambda x: len(re.findall('nlp', x)))\r\n",
    "test_df['pyspark_counts'] = test_df['resumes'].apply(lambda x: len(re.findall('pyspark', x)))\r\n",
    "test_df['hadoop_counts'] = test_df['resumes'].apply(lambda x: len(re.findall('hadoop', x)))\r\n",
    "test_df['data_analysis_counts'] = test_df['resumes'].apply(lambda x: len(re.findall('data analysis', x)))\r\n",
    "test_df['lustering_counts'] = test_df['resumes'].apply(lambda x: len(re.findall('clustering', x)))\r\n",
    "test_df['lr_counts'] = test_df['resumes'].apply(lambda x: len(re.findall('logistic regression', x)))\r\n",
    "test_df['classification_counts'] = test_df['resumes'].apply(lambda x: len(re.findall('classification', x)))\r\n",
    "test_df['sk_counts'] = test_df['resumes'].apply(lambda x: len(re.findall('sciKit learn', x)))\r\n",
    "test_df['pytorch_counts'] = test_df['resumes'].apply(lambda x: len(re.findall('pytorch', x)))\r\n",
    "test_df['cnn_counts'] = test_df['resumes'].apply(lambda x: len(re.findall('cnn', x)))\r\n",
    "test_df['rnn_counts'] = test_df['resumes'].apply(lambda x: len(re.findall('rnn', x)))\r\n",
    "test_df['gans_counts'] = test_df['resumes'].apply(lambda x: len(re.findall('gans', x)))\r\n",
    "test_df['nltk_counts'] = test_df['resumes'].apply(lambda x: len(re.findall('nltk', x)))\r\n",
    "test_df['spacy_counts'] = test_df['resumes'].apply(lambda x: len(re.findall('spacy', x)))\r\n",
    "test_df['transformer_counts'] = test_df['resumes'].apply(lambda x: len(re.findall('transformer', x)))\r\n",
    "test_df['django_counts'] = test_df['resumes'].apply(lambda x: len(re.findall('django', x)))\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "test_df['feature1'] = test_df['neural_network_counts'] + test_df['tf_counts'] + test_df['ml_counts']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\r\n",
    "max_vocab_length = 10000\r\n",
    "max_length = 100\r\n",
    "\r\n",
    "text_vectorizer = TextVectorization(max_tokens=None,\r\n",
    "                                    standardize=\"lower_and_strip_punctuation\",\r\n",
    "                                    split=\"whitespace\", \r\n",
    "                                    ngrams=None,\r\n",
    "                                    output_mode=\"int\",\r\n",
    "                                    output_sequence_length=None)\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "text_vectorizer = TextVectorization(max_tokens=max_vocab_length,\r\n",
    "                                    output_mode=\"int\",\r\n",
    "                                    output_sequence_length=max_length)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "filtered_resume_list_train = list(train_df.resumes)\r\n",
    "filtered_resume_list_test = list(test_df.resumes)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "filtered_resume_list_train[0]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import warnings\r\n",
    "warnings.filterwarnings(action = 'ignore')\r\n",
    "  \r\n",
    "import gensim\r\n",
    "from gensim.models import Word2Vec"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "text_vectorizer.adapt(filtered_resume_list_train)\r\n",
    "text_vectorizer.adapt(filtered_resume_list_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.feature_selection import mutual_info_regression\r\n",
    "def make_mi_scores(X, y):\r\n",
    "    mi_scores = mutual_info_regression(X, y)\r\n",
    "    mi_scores = pd.Series(mi_scores, name=\"MI Scores\", index=X.columns)\r\n",
    "    mi_scores = mi_scores.sort_values(ascending=False)\r\n",
    "    return round(mi_scores, 3)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(train_df.head(5))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "train_df.shape, test_df.shape"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "train_df.drop('resumes', axis = 1, inplace=True)\r\n",
    "test_df.drop('resumes', axis = 1, inplace=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "x = train_df.drop('Match Percentage', axis = 1)\r\n",
    "y = train_df['Match Percentage']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "mi_score1 = make_mi_scores(x, y)\r\n",
    "print(mi_score1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# feature selection\r\n",
    "from sklearn.feature_selection import SelectKBest, chi2, f_regression\r\n",
    "selector = SelectKBest(f_regression, k=25)\r\n",
    "X = selector.fit_transform(x, y)\r\n",
    "test_df = selector.transform(test_df)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#splitting the dataset into train and test set.\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "x_train,x_test,y_train,y_test = train_test_split(X,y, test_size=0.15, random_state = 31)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "len(x_train), len(x_test), len(y_train), len(y_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\r\n",
    "rf_reg = RandomForestRegressor().fit(x_train, y_train)\r\n",
    "rf_reg.score(x_test, y_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def submission(model, test):\r\n",
    "    test1 = pd.read_csv('dataset/test.csv')\r\n",
    "    preds = model.predict(test)\r\n",
    "    prediction = pd.DataFrame(preds, columns = ['Match Percentage'])\r\n",
    "    sub_df = pd.concat([test1, prediction], axis = 1)\r\n",
    "    return sub_df\r\n",
    "\r\n",
    "sub = submission(rf_reg, test_df)\r\n",
    "sub.to_csv('submission file/Submission-7.csv')\r\n",
    "print(sub.head())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "%%time\r\n",
    "\r\n",
    "rfcv_grid = {\"n_estimators\": np.arange(100, 1200, 100),\r\n",
    "            'criterion' : ['mse', 'mae'],\r\n",
    "           \"max_depth\": [None, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\r\n",
    "           \"min_samples_split\": np.arange(2, 20, 2),\r\n",
    "           \"min_samples_leaf\": np.arange(1, 20, 2),\r\n",
    "           'max_features' : ['auto', 'sqrt']}\r\n",
    "\r\n",
    "rfcv_clf = RandomizedSearchCV(RandomForestRegressor(),\r\n",
    "                           param_distributions = rfcv_grid,\r\n",
    "                           cv=5,\r\n",
    "                           n_iter=300,\r\n",
    "                           verbose=True)\r\n",
    "\r\n",
    "rfcv_clf.fit(x, y)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "rfcv_clf.best_params_"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5 64-bit"
  },
  "interpreter": {
   "hash": "0bd2b4fb9f3446da4d8f55e0ab2f46c8924547cca4f6669133edbde87e094ed0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}