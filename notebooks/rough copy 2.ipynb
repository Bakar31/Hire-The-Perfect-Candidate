{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# required libraries\r\n",
    "import os\r\n",
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "from pdfminer import high_level\r\n",
    "\r\n",
    "train = pd.read_csv('dataset/train.csv')\r\n",
    "test = pd.read_csv('dataset/test.csv')\r\n",
    "\r\n",
    "#paths\r\n",
    "train_path = \"dataset/trainResumes/\"\r\n",
    "test_path = \"dataset/testResumes/\"\r\n",
    "\r\n",
    "# epty list for resumes text\r\n",
    "train_resumes = []\r\n",
    "test_resumes = []\r\n",
    "\r\n",
    "# ids\r\n",
    "ids = list(train.CandidateID)\r\n",
    "test_ids = list(test.CandidateID)\r\n",
    "\r\n",
    "# pdf2string\r\n",
    "def pdf2string_train(path, ids, resumes):\r\n",
    "    for i in ids:\r\n",
    "        main_path = path+i+'.pdf'\r\n",
    "        text = high_level.extract_text(main_path)\r\n",
    "        str_list = text.split()\r\n",
    "        str_list = str_list[:]\r\n",
    "        string = ' '.join(str_list)\r\n",
    "        resumes.append(string)\r\n",
    "        \r\n",
    "\r\n",
    "def pdf2string_test(path, test_ids, resumes):\r\n",
    "    for i in test_ids:\r\n",
    "        main_path = path+i+'.pdf'\r\n",
    "        text = high_level.extract_text(main_path)\r\n",
    "        str_list = text.split()\r\n",
    "        str_list = str_list[:]\r\n",
    "        string = ' '.join(str_list)\r\n",
    "        resumes.append(string)\r\n",
    "\r\n",
    "\r\n",
    "pdf2string_train(train_path, ids, train_resumes)\r\n",
    "pdf2string_test(test_path,  test_ids, test_resumes)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "print(train_resumes[0])\r\n",
    "print('==================')\r\n",
    "print(test_resumes[0])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "L I A M A N D R E W S F R E S H E R WORK EXPERIENCE DICTIS making. Intern Trainee, Jan 2020 to Apr 2020 Responsible for performing and helping in decision EXECUTIVE SUMMARY Fresher with strong statistical and analytic capabilities. Someone who is driven by the passion for problem solving. Though I am from Civil Engineering background I have always been fascinated with data and how Machine Learning is evolving with iit. PERSONAL SKILLS Data Analyst, Data Mining, Data Visualization, Machine Learning, Linear Regression, Statistical Modeling, Predictive Modeling, SQL Server, Oracle, Python. PROJECTS EXTRA-CURRICULARS Data Preprocessing with Python Data Visualization with Power BI ACADEMIC PROFILE Railway Signals Determiner using relay weight system. 2020 B.Tech(Civil) Garodia Institute of Technosciences,\n",
      "==================\n",
      "GRACE BAILRY M A C H I N E L E A R N I N G D E V E L O P M E N T A N D D E P L O Y M E N T PERSONAL PROFILE WORK BACKGROUND I am a software engineer who has worked on several computer vision projects and their end to end deployment. I am looking to join as a Machine Learning developer to closely work on problems and increase my grasp over the domain. Eximius Design Pvt ltd company Software Development and Deployment Engineer Apr 2019 to Till Date Implementing multiple components of a face identification system which include face alignment and landmark detection. Improving the validation pipeline of face recognition: Collected data under different lighting conditions. Performed Image manipulation operations on data to increase the accuracy of the pipeline. SKILLS EDUCATION Software Engineer/Developer, Software Development, Project Management, Machine Learning, Computer Vision, OpenCV, Python, C++, Ruby, Learning Algorithm. B.Tech in Electronics & Computers from DVR College of Engineering & Technology in 2017 Post Graduation in Software Development from CDAC Noida in 2019 PROJECTS OTHER ACTIVITIES Scalable Projects and their Deployment - SDLC Pioneers Deployment of End to End ML Projects - KVCC'20 Workshop Clustering of images based on feature management Creating a recommender system to understand false alarms on support side of real time services.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "import spacy\r\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\r\n",
    "nlp = spacy.load('en_core_web_sm')\r\n",
    "\r\n",
    "punctuations = list('''!()-[]{};:'\"\\,<>./?@#$%^&*_~''')\r\n",
    "\r\n",
    "def text_processing(resume):   \r\n",
    "\r\n",
    "    resume = nlp(resume)\r\n",
    "    token_list = []\r\n",
    "    for token in resume:\r\n",
    "        token_list.append(token.text)\r\n",
    "\r\n",
    "    filtered_sentence =[] \r\n",
    "    for word in token_list:\r\n",
    "        lexeme = nlp.vocab[word]\r\n",
    "        if lexeme.is_stop == False:\r\n",
    "            filtered_sentence.append(word) \r\n",
    "\r\n",
    "    filtered_sentence_2 = []\r\n",
    "    for word in filtered_sentence:\r\n",
    "        if word not in punctuations:\r\n",
    "            filtered_sentence_2.append(word)\r\n",
    "    \r\n",
    "    Stem_words = []\r\n",
    "    sentence = ' '.join(filtered_sentence_2)\r\n",
    "    doc = nlp(sentence)\r\n",
    "    for word in doc:\r\n",
    "        Stem_words.append(word.lemma_)\r\n",
    "\r\n",
    "    main_text = ' '.join(Stem_words)\r\n",
    "    main_text = main_text.lower()\r\n",
    "    return main_text"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "processed_resumes_train = []\r\n",
    "processed_resumes_test = []\r\n",
    "\r\n",
    "for  resume in train_resumes:\r\n",
    "    processed_resume = text_processing(resume)\r\n",
    "    processed_resumes_train.append(processed_resume)\r\n",
    "\r\n",
    "for  resume in test_resumes:\r\n",
    "    processed_resume = text_processing(resume)\r\n",
    "    processed_resumes_test.append(processed_resume)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "print(len(processed_resumes_train))\r\n",
    "print(len(processed_resumes_test))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "90\n",
      "60\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "print(processed_resumes_train[0])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "l m n d r e w s f r e s h e r work experience dictis make intern trainee jan 2020 apr 2020 responsible perform help decision executive summary fresher strong statistical analytic capability drive passion problem solve civil engineering background fascinated datum machine learning evolve iit personal skills data analyst data mining data visualization machine learning linear regression statistical modeling predictive modeling sql server oracle python project extra curriculars datum preprocesse python data visualization power bi academic profile railway signals determiner relay weight system 2020 b.tech(civil garodia institute technosciences\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5 64-bit"
  },
  "interpreter": {
   "hash": "0bd2b4fb9f3446da4d8f55e0ab2f46c8924547cca4f6669133edbde87e094ed0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}