{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "# required libraries\r\n",
    "import os\r\n",
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "from pdfminer import high_level\r\n",
    "\r\n",
    "#paths\r\n",
    "train_path = \"dataset/trainResumes/\"\r\n",
    "test_path = \"dataset/testResumes/\"\r\n",
    "\r\n",
    "# epty list for resumes text\r\n",
    "train_resumes = []\r\n",
    "test_resumes = []\r\n",
    "\r\n",
    "# pdf2string\r\n",
    "def pdf2string(path, resumes):\r\n",
    "    for i in os.listdir(path):\r\n",
    "        main_path = path+i\r\n",
    "        text = high_level.extract_text(main_path)\r\n",
    "        str_list = text.split()\r\n",
    "        str_list = str_list[:]\r\n",
    "        string = ' '.join(str_list)\r\n",
    "        resumes.append(string)\r\n",
    "\r\n",
    "pdf2string(train_path, train_resumes)\r\n",
    "pdf2string(test_path, test_resumes)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "import spacy\r\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\r\n",
    "nlp = spacy.load('en_core_web_sm')\r\n",
    "\r\n",
    "needless_words = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U',\r\n",
    "'V', 'W', 'X', 'Y', 'Z']\r\n",
    "punctuations = list('''!()-[]{};:'\"\\,<>./?@#$%^&*_~''')\r\n",
    "\r\n",
    "def text_processing(resume):   \r\n",
    "\r\n",
    "    resume = nlp(resume)\r\n",
    "    token_list = []\r\n",
    "    for token in resume:\r\n",
    "        token_list.append(token.text)\r\n",
    "\r\n",
    "    filtered_sentence =[] \r\n",
    "    for word in token_list:\r\n",
    "        lexeme = nlp.vocab[word]\r\n",
    "        if lexeme.is_stop == False:\r\n",
    "            filtered_sentence.append(word) \r\n",
    "\r\n",
    "    # further filter\r\n",
    "    filtered_sentence_2 = []\r\n",
    "    for word in filtered_sentence:\r\n",
    "        if word not in needless_words:\r\n",
    "            filtered_sentence_2.append(word)\r\n",
    "\r\n",
    "    filtered_sentence_3 = []\r\n",
    "    for word in filtered_sentence_2:\r\n",
    "        if word not in punctuations:\r\n",
    "            filtered_sentence_3.append(word)\r\n",
    "    \r\n",
    "    Stem_words = []\r\n",
    "    sentence = ' '.join(filtered_sentence_3)\r\n",
    "    doc = nlp(sentence)\r\n",
    "    for word in doc:\r\n",
    "        Stem_words.append(word.lemma_)\r\n",
    "\r\n",
    "    main_text = ' '.join(Stem_words)\r\n",
    "    main_text = main_text.lower()\r\n",
    "    return main_text"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "processed_resumes_train = []\r\n",
    "processed_resumes_test = []\r\n",
    "\r\n",
    "for  resume in train_resumes:\r\n",
    "    processed_resume = text_processing(resume)\r\n",
    "    processed_resumes_train.append(processed_resume)\r\n",
    "\r\n",
    "for  resume in test_resumes:\r\n",
    "    processed_resume = text_processing(resume)\r\n",
    "    processed_resumes_test.append(processed_resume)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "print(len(processed_resumes_train))\r\n",
    "print(len(processed_resumes_test))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "90\n",
      "60\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "print(processed_resumes_train[2])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "associate analyst skills certified data analyst degree electronics engineering hand experience analyze interpret datum good numerical accuracy python machine learning mysql data mining deep learning data analysis computer vision flask api predictive modeling aws scikit learn numpy statistical analysis multivariate analysis decision trees random forest xgboost nlp project work experience deep learning base pattern match auto color grade python amz loans mortgages erc analytics jun 2019 till date qualification google cloud certified handling datum employee find retention factor employee satisfaction worked closely hr team find balance beneficial employee company education b.tech b.e. electronics telecommunication nagpur university 2019\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "train = pd.read_csv('dataset/train.csv')\r\n",
    "test = pd.read_csv('dataset/test.csv')\r\n",
    "\r\n",
    "def dataframe(resume_list, df):\r\n",
    "    resumes =  pd.DataFrame(resume_list, columns = ['resumes'])\r\n",
    "    dataframe = pd.concat([df, resumes], axis = 1)\r\n",
    "    dataframe.drop('CandidateID', axis = 1, inplace = True)\r\n",
    "    return dataframe\r\n",
    "\r\n",
    "train_df = dataframe(processed_resumes_train, train)\r\n",
    "test_df = dataframe(processed_resumes_test, test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "import re"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "# train features\r\n",
    "train_df['words_counts'] = train_df['resumes'].apply(lambda x: len(str(x).split()))\r\n",
    "train_df['char_counts'] = train_df['resumes'].apply(lambda x: len(str(x)))\r\n",
    "train_df['avg_word_len'] = train_df['char_counts']/train_df['words_counts']\r\n",
    "train_df['ml_counts'] = train_df['resumes'].apply(lambda x: len(re.findall('machine learning', x)))\r\n",
    "train_df['ml_engineer_counts'] = train_df['resumes'].apply(lambda x: len(re.findall('machine learning engineer', x)))\r\n",
    "train_df['analytics_counts'] = train_df['resumes'].apply(lambda x: len(re.findall('analytics', x)))\r\n",
    "train_df['degree_counts'] = train_df['resumes'].apply(lambda x: len(re.findall('master degree', x)))\r\n",
    "train_df['degree_counts_2'] = train_df['resumes'].apply(lambda x: len(re.findall('msc', x)))\r\n",
    "train_df['degree_counts_3'] = train_df['resumes'].apply(lambda x: len(re.findall('degree', x)))\r\n",
    "train_df['deep_learning_counts'] = train_df['resumes'].apply(lambda x: len(re.findall('deep learning', x)))\r\n",
    "train_df['tf_counts'] = train_df['resumes'].apply(lambda x: len(re.findall('tensorflow', x)))\r\n",
    "train_df['neural_network_counts'] = train_df['resumes'].apply(lambda x: len(re.findall('neural network', x)))\r\n",
    "train_df['nlp_counts'] = train_df['resumes'].apply(lambda x: len(re.findall('natural language processing', x)))\r\n",
    "train_df['nlp_counts_2'] = train_df['resumes'].apply(lambda x: len(re.findall('nlp', x)))\r\n",
    "train_df['pyspark_counts'] = train_df['resumes'].apply(lambda x: len(re.findall('pyspark', x)))\r\n",
    "train_df['hadoop_counts'] = train_df['resumes'].apply(lambda x: len(re.findall('hadoop', x)))\r\n",
    "train_df['data_analysis_counts'] = train_df['resumes'].apply(lambda x: len(re.findall('data analysis', x)))\r\n",
    "train_df['lustering_counts'] = train_df['resumes'].apply(lambda x: len(re.findall('clustering', x)))\r\n",
    "train_df['lr_counts'] = train_df['resumes'].apply(lambda x: len(re.findall('logistic regression', x)))\r\n",
    "train_df['classification_counts'] = train_df['resumes'].apply(lambda x: len(re.findall('classification', x)))\r\n",
    "train_df['sk_counts'] = train_df['resumes'].apply(lambda x: len(re.findall('sciKit learn', x)))\r\n",
    "train_df['pytorch_counts'] = train_df['resumes'].apply(lambda x: len(re.findall('pytorch', x)))\r\n",
    "train_df['cnn_counts'] = train_df['resumes'].apply(lambda x: len(re.findall('cnn', x)))\r\n",
    "train_df['rnn_counts'] = train_df['resumes'].apply(lambda x: len(re.findall('rnn', x)))\r\n",
    "train_df['gans_counts'] = train_df['resumes'].apply(lambda x: len(re.findall('gans', x)))\r\n",
    "train_df['nltk_counts'] = train_df['resumes'].apply(lambda x: len(re.findall('nltk', x)))\r\n",
    "train_df['spacy_counts'] = train_df['resumes'].apply(lambda x: len(re.findall('spacy', x)))\r\n",
    "train_df['transformer_counts'] = train_df['resumes'].apply(lambda x: len(re.findall('transformer', x)))\r\n",
    "train_df['django_counts'] = train_df['resumes'].apply(lambda x: len(re.findall('django', x)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "train_df['feature1'] = train_df['neural_network_counts'] + train_df['tf_counts'] + train_df['ml_counts']\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "# test features\r\n",
    "test_df['words_counts'] = test_df['resumes'].apply(lambda x: len(str(x).split()))\r\n",
    "test_df['char_counts'] = test_df['resumes'].apply(lambda x: len(str(x)))\r\n",
    "test_df['avg_word_len'] = test_df['char_counts']/train_df['words_counts']\r\n",
    "test_df['ml_counts'] = test_df['resumes'].apply(lambda x: len(re.findall('machine learning', x)))\r\n",
    "test_df['ml_engineer_counts'] = test_df['resumes'].apply(lambda x: len(re.findall('machine learning engineer', x)))\r\n",
    "test_df['analytics_counts'] = test_df['resumes'].apply(lambda x: len(re.findall('analytics', x)))\r\n",
    "test_df['degree_counts'] = test_df['resumes'].apply(lambda x: len(re.findall('master degree', x)))\r\n",
    "test_df['degree_counts_2'] = test_df['resumes'].apply(lambda x: len(re.findall('msc', x)))\r\n",
    "test_df['degree_counts_3'] = test_df['resumes'].apply(lambda x: len(re.findall('degree', x)))\r\n",
    "test_df['deep_learning_counts'] = test_df['resumes'].apply(lambda x: len(re.findall('deep learning', x)))\r\n",
    "test_df['tf_counts'] = test_df['resumes'].apply(lambda x: len(re.findall('tensorflow', x)))\r\n",
    "test_df['neural_network_counts'] = test_df['resumes'].apply(lambda x: len(re.findall('neural network', x)))\r\n",
    "test_df['nlp_counts'] = test_df['resumes'].apply(lambda x: len(re.findall('natural language processing', x)))\r\n",
    "test_df['nlp_counts_2'] = test_df['resumes'].apply(lambda x: len(re.findall('nlp', x)))\r\n",
    "test_df['pyspark_counts'] = test_df['resumes'].apply(lambda x: len(re.findall('pyspark', x)))\r\n",
    "test_df['hadoop_counts'] = test_df['resumes'].apply(lambda x: len(re.findall('hadoop', x)))\r\n",
    "test_df['data_analysis_counts'] = test_df['resumes'].apply(lambda x: len(re.findall('data analysis', x)))\r\n",
    "test_df['lustering_counts'] = test_df['resumes'].apply(lambda x: len(re.findall('clustering', x)))\r\n",
    "test_df['lr_counts'] = test_df['resumes'].apply(lambda x: len(re.findall('logistic regression', x)))\r\n",
    "test_df['classification_counts'] = test_df['resumes'].apply(lambda x: len(re.findall('classification', x)))\r\n",
    "test_df['sk_counts'] = test_df['resumes'].apply(lambda x: len(re.findall('sciKit learn', x)))\r\n",
    "test_df['pytorch_counts'] = test_df['resumes'].apply(lambda x: len(re.findall('pytorch', x)))\r\n",
    "test_df['cnn_counts'] = test_df['resumes'].apply(lambda x: len(re.findall('cnn', x)))\r\n",
    "test_df['rnn_counts'] = test_df['resumes'].apply(lambda x: len(re.findall('rnn', x)))\r\n",
    "test_df['gans_counts'] = test_df['resumes'].apply(lambda x: len(re.findall('gans', x)))\r\n",
    "test_df['nltk_counts'] = test_df['resumes'].apply(lambda x: len(re.findall('nltk', x)))\r\n",
    "test_df['spacy_counts'] = test_df['resumes'].apply(lambda x: len(re.findall('spacy', x)))\r\n",
    "test_df['transformer_counts'] = test_df['resumes'].apply(lambda x: len(re.findall('transformer', x)))\r\n",
    "test_df['django_counts'] = test_df['resumes'].apply(lambda x: len(re.findall('django', x)))\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "test_df['feature1'] = test_df['neural_network_counts'] + test_df['tf_counts'] + test_df['ml_counts']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\r\n",
    "max_vocab_length = 10000\r\n",
    "max_length = 100\r\n",
    "\r\n",
    "text_vectorizer = TextVectorization(max_tokens=None,\r\n",
    "                                    standardize=\"lower_and_strip_punctuation\",\r\n",
    "                                    split=\"whitespace\", \r\n",
    "                                    ngrams=None,\r\n",
    "                                    output_mode=\"int\",\r\n",
    "                                    output_sequence_length=None)\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "text_vectorizer = TextVectorization(max_tokens=max_vocab_length,\r\n",
    "                                    output_mode=\"int\",\r\n",
    "                                    output_sequence_length=max_length)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "filtered_resume_list_train = list(train_df.resumes)\r\n",
    "filtered_resume_list_test = list(test_df.resumes)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "filtered_resume_list_train[0]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'jacob smith personal profile work background actively seek opportunity data analyst machine learning engineer goal discover new business strategy create impact datum drive analytical decision lead business success expert hub intern 2019 team design develop smart parking system base object recognition skill education b. tech ece vit ap university 2020 python sql mysql tableau power bi pandas numpy matplotlib excel machine learning aws(emr ec2,s3 cloud hive(hql excel project music genre classification face eye smile recognition activity deep learning masters machine learning'"
      ]
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "import warnings\r\n",
    "warnings.filterwarnings(action = 'ignore')\r\n",
    "  \r\n",
    "import gensim\r\n",
    "from gensim.models import Word2Vec"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "text_vectorizer.adapt(filtered_resume_list_train)\r\n",
    "text_vectorizer.adapt(filtered_resume_list_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "from sklearn.feature_selection import mutual_info_regression\r\n",
    "def make_mi_scores(X, y):\r\n",
    "    mi_scores = mutual_info_regression(X, y)\r\n",
    "    mi_scores = pd.Series(mi_scores, name=\"MI Scores\", index=X.columns)\r\n",
    "    mi_scores = mi_scores.sort_values(ascending=False)\r\n",
    "    return round(mi_scores, 3)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "print(train_df.head(5))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "   Match Percentage                                            resumes  \\\n",
      "0             13.60  jacob smith personal profile work background a...   \n",
      "1             36.63  brianna williams executive profile work experi...   \n",
      "2             54.93  associate analyst skills certified data analys...   \n",
      "3             41.46  python machine learn deep learning data analys...   \n",
      "4             48.91  jennifer armstrong fresher computer vision mac...   \n",
      "\n",
      "   words_counts  char_counts  avg_word_len  ml_counts  ml_engineer_counts  \\\n",
      "0            81          579      7.148148          3                   1   \n",
      "1           124          978      7.887097          1                   0   \n",
      "2            97          743      7.659794          1                   0   \n",
      "3            86          650      7.558140          1                   0   \n",
      "4            68          538      7.911765          1                   1   \n",
      "\n",
      "   analytics_counts  degree_counts  degree_counts_2  ...  sk_counts  \\\n",
      "0                 0              0                0  ...          0   \n",
      "1                 0              0                1  ...          0   \n",
      "2                 1              0                0  ...          0   \n",
      "3                 0              0                0  ...          0   \n",
      "4                 0              0                0  ...          0   \n",
      "\n",
      "   pytorch_counts  cnn_counts  rnn_counts  gans_counts  nltk_counts  \\\n",
      "0               0           0           0            0            0   \n",
      "1               0           0           0            0            0   \n",
      "2               0           0           0            0            0   \n",
      "3               0           0           0            0            0   \n",
      "4               0           0           0            0            0   \n",
      "\n",
      "   spacy_counts  transformer_counts  django_counts  feature1  \n",
      "0             0                   0              0         3  \n",
      "1             0                   0              0         2  \n",
      "2             0                   0              0         1  \n",
      "3             0                   0              0         1  \n",
      "4             0                   0              0         2  \n",
      "\n",
      "[5 rows x 32 columns]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "source": [
    "train_df.shape, test_df.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((90, 32), (60, 31))"
      ]
     },
     "metadata": {},
     "execution_count": 36
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "source": [
    "train_df.drop('resumes', axis = 1, inplace=True)\r\n",
    "test_df.drop('resumes', axis = 1, inplace=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "source": [
    "x = train_df.drop('Match Percentage', axis = 1)\r\n",
    "y = train_df['Match Percentage']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "source": [
    "mi_score1 = make_mi_scores(x, y)\r\n",
    "print(mi_score1)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "neural_network_counts    0.089\n",
      "tf_counts                0.052\n",
      "lr_counts                0.035\n",
      "nlp_counts               0.033\n",
      "hadoop_counts            0.029\n",
      "pytorch_counts           0.023\n",
      "rnn_counts               0.020\n",
      "django_counts            0.017\n",
      "ml_counts                0.013\n",
      "lustering_counts         0.012\n",
      "cnn_counts               0.011\n",
      "data_analysis_counts     0.005\n",
      "spacy_counts             0.004\n",
      "nltk_counts              0.001\n",
      "gans_counts              0.000\n",
      "sk_counts                0.000\n",
      "transformer_counts       0.000\n",
      "classification_counts    0.000\n",
      "words_counts             0.000\n",
      "char_counts              0.000\n",
      "pyspark_counts           0.000\n",
      "nlp_counts_2             0.000\n",
      "deep_learning_counts     0.000\n",
      "degree_counts_3          0.000\n",
      "degree_counts_2          0.000\n",
      "degree_counts            0.000\n",
      "analytics_counts         0.000\n",
      "ml_engineer_counts       0.000\n",
      "avg_word_len             0.000\n",
      "feature1                 0.000\n",
      "Name: MI Scores, dtype: float64\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "source": [
    "# feature selection\r\n",
    "from sklearn.feature_selection import SelectKBest, chi2, f_regression\r\n",
    "selector = SelectKBest(f_regression, k=25)\r\n",
    "X = selector.fit_transform(x, y)\r\n",
    "test_df = selector.transform(test_df)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "source": [
    "#splitting the dataset into train and test set.\r\n",
    "#from sklearn.model_selection import train_test_split\r\n",
    "#x_train,x_test,y_train,y_test = train_test_split(X,y, test_size=0.15, random_state = 31)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "source": [
    "#len(x_train), len(x_test), len(y_train), len(y_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\r\n",
    "rf_reg = RandomForestRegressor(n_estimators = 200).fit(X, y)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "source": [
    "def submission(model, test):\r\n",
    "    test1 = pd.read_csv('dataset/test.csv')\r\n",
    "    preds = model.predict(test)\r\n",
    "    prediction = pd.DataFrame(preds, columns = ['Match Percentage'])\r\n",
    "    sub_df = pd.concat([test1, prediction], axis = 1)\r\n",
    "    return sub_df\r\n",
    "\r\n",
    "sub = submission(rf_reg, test_df)\r\n",
    "sub.to_csv('submission file/Submission-11.csv')\r\n",
    "print(sub.head())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "     CandidateID  Match Percentage\n",
      "0  candidate_014          44.45955\n",
      "1  candidate_098          23.57120\n",
      "2  candidate_075          28.23695\n",
      "3  candidate_016          43.94650\n",
      "4  candidate_131          43.70865\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "source": [
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "source": [
    "rfcv_grid = {\"n_estimators\": np.arange(100, 1100, 100),\r\n",
    "            #'criterion' : ['mse', 'mae'],\r\n",
    "           \"max_depth\": [None, 1, 2, 3, 5, 7, 9, 10],\r\n",
    "           \"min_samples_split\": np.arange(2, 12, 2),\r\n",
    "           \"min_samples_leaf\": np.arange(1, 12, 2)\r\n",
    "           #'max_features' : ['auto', 'sqrt']\r\n",
    "           }\r\n",
    "\r\n",
    "rfcv_clf = GridSearchCV(RandomForestRegressor(),\r\n",
    "                           param_grid = rfcv_grid,\r\n",
    "                           cv=2,\r\n",
    "                           verbose=True)\r\n",
    "\r\n",
    "rfcv_clf.fit(X, y)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 2 folds for each of 2400 candidates, totalling 4800 fits\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "GridSearchCV(cv=2, estimator=RandomForestRegressor(),\n",
       "             param_grid={'max_depth': [None, 1, 2, 3, 5, 7, 9, 10],\n",
       "                         'min_samples_leaf': array([ 1,  3,  5,  7,  9, 11]),\n",
       "                         'min_samples_split': array([ 2,  4,  6,  8, 10]),\n",
       "                         'n_estimators': array([ 100,  200,  300,  400,  500,  600,  700,  800,  900, 1000])},\n",
       "             verbose=True)"
      ]
     },
     "metadata": {},
     "execution_count": 59
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "source": [
    "rfcv_clf.best_params_"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'max_depth': 2,\n",
       " 'min_samples_leaf': 11,\n",
       " 'min_samples_split': 8,\n",
       " 'n_estimators': 200}"
      ]
     },
     "metadata": {},
     "execution_count": 60
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5 64-bit"
  },
  "interpreter": {
   "hash": "0bd2b4fb9f3446da4d8f55e0ab2f46c8924547cca4f6669133edbde87e094ed0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}